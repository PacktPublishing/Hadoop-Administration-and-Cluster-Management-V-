We can control the individual service on a node:
$ hadoop-daemon.sh start/stop namenode
$ hadoop-daemon.sh start/stop datanode

We can control the individual service on a node:
$ stop-dfs.sh
$ start-dfs.sh

Yarn services

$ yarn-daemon.sh start/stop resourcemanager
$ yarn-daemon.sh start/stop nodemanager

$ stop-yarn.sh
$ start-yarn.sh

$ stop-all.sh
$ start-all.sh


Hadoop Upgrade

1. Stop all client applications running on the MapReduce cluster.

2. Perform a filesystem check 
	hadoop fsck / -files -blocks -locations > dfs-v-old-fsck-1.log
	
3. Save a complete listing of the HDFS namespace to a local file
	hadoop dfs -lsr / > dfs-v-old-lsr-1.log
	
4. Create a list of DataNodes participating in the cluster:
	hadoop dfsadmin -report > dfs-v-old-report-1.log
	
5. Optionally backup HDFS data

6. Upgrade process:
	Point to the new directory, update environment variables.
	
7. hadoop-daemon.sh start namenode -upgrade

8. hadoop dfsadmin -upgradeProgress status

9. Now start the datanode, after pointing to the new hadoop directory

10. hadoop dfsadmin -safemode get

11. hadoop dfsadmin -finalizeUpgrade


